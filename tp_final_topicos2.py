# -*- coding: utf-8 -*-
"""tp_final_topicos2.ipynb

Automatically generated by Colaboratory.

Original file is located at
    https://colab.research.google.com/drive/1wzFBkpgvHLcpnaoYZS7NLwO11kPrR_Pb
"""



"""## Paso 1: Cargar los datos.
Levantamos los datos de los pacientes
"""

# Read data from file

import numpy as np
import pandas as pd

file_name = 'data/datos_de_pacientes_5000.csv'
data = pd.read_csv(file_name, index_col=0)

print("Datos de pacientes")
print("-----------------------")
print(data)

"""## Paso 2: Preprocesar los datos.

Separamos los datos de entrada de las etiquetas

Separamos conjuntos de training, validación y testing según sea necesario
"""

# Date preprocessing
from sklearn.model_selection import train_test_split
from sklearn.preprocessing import MinMaxScaler

# Scaling numerical variables
scaler = MinMaxScaler()

# Separate the data from the target labels
X = data.drop(['riesgo_cardiaco'], axis=1)
y = np.array(data['riesgo_cardiaco'])


# Split the data into training and testing sets
X_train, X_test, y_train, y_test = train_test_split(X, y, test_size=0.2)

# For training set
scaled_X_train = scaler.fit_transform(X_train)
scaled_X_train = pd.DataFrame(scaled_X_train, columns=X_train.columns)

# For testing set
scaled_X_test = scaler.transform(X_test)
scaled_X_test = pd.DataFrame(scaled_X_test, columns=X_test.columns)

print("Set de training")
print("---------------")
print(scaled_X_train)

print("Set de test")
print("------------")
print(scaled_X_test)

"""##Paso 3: Armo la red"""

# Build the Neural Network
import numpy as np
from tensorflow import keras
from keras.models import Sequential
from keras.layers import Dense
from tensorflow.keras.optimizers import Adam

# Create the model
model = Sequential()

# 6 INPUT (colesterol, presión, glucosa, edad, sobrepeso, tabaquismo)
model.add(Dense(50, input_shape=(6,), activation='relu', kernel_initializer='uniform'))
model.add(Dense(25, activation='relu', kernel_initializer='random_normal'))
model.add(Dense(35, activation='relu', kernel_initializer='random_normal'))
model.add(Dense(1, activation='sigmoid')) # Sigmoid activation in the output layer

# Compile
model.compile(loss='binary_crossentropy', optimizer=Adam(learning_rate=0.01))
model.summary()

"""##Paso 4: Entreno la red neuronal"""

# Training
historicalModel = model.fit(scaled_X_train, y_train, validation_split=0.2, epochs=200, batch_size=32, verbose=2)

"""##Paso 5: Evaluo la red"""

# Make predictions with the model
y_pred = model.predict(scaled_X_test)

import matplotlib.pyplot as plt

# Visualización de la pérdida
plt.plot(historicalModel.history['loss'], label='Training Loss')
plt.plot(historicalModel.history['val_loss'], label='Validation Loss')
plt.xlabel('Epoch')
plt.ylabel('Loss')
plt.legend()
plt.show()

# Evaluate
result = model.evaluate(scaled_X_test, y_test)
print("Evaluate the model: ",result)


plt.xlabel("# Epoca")
plt.ylabel("Magnitud de pérdida")
plt.plot(historicalModel.history["loss"])
plt.legend()
plt.show()

print("Datos a predecir:")
print(X_train[:3])
print("-----------------")

print("Resultados obtenidos:")
print(y_pred[:3])
print("Valores correctos:")
print(y_test[:3])

model.save("model.keras")
model = keras.models.load_model("model.keras")